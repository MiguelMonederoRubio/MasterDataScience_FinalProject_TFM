{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_directory = '/Users/miguel'\n",
    "raw_data_directory = your_directory + '/raw_data'\n",
    "raw_data_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# lo del df_name no tiene sentido si luego no lo puedo llamar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# input raw data from different years (2010-2021)\n",
    "initial_year = 2010\n",
    "last_year = 2021\n",
    "next_year = initial_year + 1\n",
    "num_years = last_year - initial_year + 1\n",
    "list_of_dfs = []\n",
    "list_of_directories = []\n",
    "# format example: df_2010_2011 = pd.read_csv(raw_data_directory + '/Notas de corte de Medicina 2010_2011 - Hoja 1.csv', decimal = ',')\n",
    "\n",
    "for i in range(num_years):\n",
    "    df_name = 'df' + '_' + str(initial_year) + '_' + str(next_year)\n",
    "    directory = raw_data_directory + '/Notas de corte de Medicina ' + str(initial_year) + '_' + str(next_year) + ' - Hoja 1.csv'\n",
    "    list_of_dfs.append(df_name)\n",
    "    list_of_directories.append(directory)\n",
    "    \n",
    "    list_of_dfs[i] = pd.read_csv(list_of_directories[i], decimal = ',')\n",
    "    \n",
    "    initial_year += 1\n",
    "    next_year += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before appending all dfs, we create a column with the year, to keep track of which df the data is coming from\n",
    "initial_year = 2010\n",
    "\n",
    "for i in range(num_years):\n",
    "    list_of_dfs[i]['year'] = initial_year + i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_years):\n",
    "    dfs_unified = dfs_unified.append(list_of_dfs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the append has been done correctly: check the number of rows is the sum of all of the dfs\n",
    "\n",
    "total_number_of_rows = 0\n",
    "\n",
    "for i in range(num_years):\n",
    "    total_number_of_rows = total_number_of_rows + len(list_of_dfs[i])\n",
    "\n",
    "if total_number_of_rows != dfs_unified.shape[0]:\n",
    "    sys.exit()\n",
    "else:\n",
    "    print('append has been done correctly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dfs_unified[dfs_unified.duplicated() == True].shape[0] != 0:\n",
    "    dfs_unified.drop_duplicates()\n",
    "else:\n",
    "    print('There are no duplicates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new unique columns out of data that we already had"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_containing_text(df, text):\n",
    "    '''\n",
    "    drop columns that contain a certain string/text\n",
    "    '''\n",
    "    df = df[df.columns.drop(list(df.filter(regex=text)))]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified = drop_columns_containing_text(dfs_unified, 'Sobre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to keep track of raw columns, to afterwards drop them\n",
    "dfs_unified_raw_columns = dfs_unified.columns.tolist()\n",
    "# 'year' was created before and is not a raw column\n",
    "dfs_unified_raw_columns.remove('year')\n",
    "#dfs_unified_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiene sentido copiar solo not null data y no toda????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data(new_col, old_col):\n",
    "    '''\n",
    "    copy not null data from one column to another\n",
    "    '''\n",
    "    dfs_unified[new_col] = np.where(dfs_unified[old_col].notnull(), dfs_unified[old_col], dfs_unified[new_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified['university'] = ''\n",
    "copy_data('university', 'Notas de corte de Medicina')\n",
    "copy_data('university', 'Universidad')\n",
    "copy_data('university', 'Facultad de Medicina')\n",
    "\n",
    "#dfs_unified['date_last_admission'] = ''\n",
    "#copy_data('date_last_admission', 'Fecha de última admisión')\n",
    "#copy_data('date_last_admission', 'Última fecha de admisión \\n(Fecha de la nota final)')\n",
    "dfs_unified['1_list'] = ''\n",
    "copy_data('1_list', '1ª Lista')\n",
    "\n",
    "dfs_unified['final_grade'] = ''\n",
    "copy_data('final_grade', 'Nota de corte final de Medicina')\n",
    "copy_data('final_grade', 'Nota de corte final')\n",
    "copy_data('final_grade', 'Nota de corte actual')\n",
    "\n",
    "\n",
    "\n",
    "#copy_data('19_list', '19ª lista')\n",
    "#copy_data('20_list', '20ª lista')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all old columns\n",
    "dfs_unified = dfs_unified.drop(dfs_unified_raw_columns, axis=1)\n",
    "\n",
    "# reset index\n",
    "#dfs_unified = dfs_unified.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified[~dfs_unified['university'].str.contains('U', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified = dfs_unified[dfs_unified['university'].str.contains('U', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified = dfs_unified[~dfs_unified['university'].str.contains('Sobre la Universidad de Santiago:', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified_columns = dfs_unified.columns.tolist()[1:]\n",
    "\n",
    "num_columns = len(dfs_unified_columns)\n",
    "\n",
    "for i in range(num_columns):\n",
    "    dfs_unified[dfs_unified_columns[i]].replace({'': np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quality check: nulls\n",
    "\n",
    "nulls_1_list = dfs_unified[dfs_unified['1_list'].isnull()].shape[0]\n",
    "nulls_final_grade = dfs_unified[dfs_unified['final_grade'].isnull()].shape[0]\n",
    "nulls_university = dfs_unified[dfs_unified['university'].isnull()].shape[0]\n",
    "\n",
    "if nulls_1_list or nulls_final_grade or nulls_university != 0:\n",
    "    sys.exit()\n",
    "else:\n",
    "    print('column 1_list has', nulls_1_list, 'null rows')\n",
    "    print('column final_grade has', nulls_final_grade, 'null rows')\n",
    "    print('column university has', nulls_university, 'null rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create consistent University names across years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified['university'] = dfs_unified['university'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_year = 2021\n",
    "dfs_unified[dfs_unified['year'] == last_year]['university'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_uni_names_2021 = dfs_unified[dfs_unified['year'] == last_year]['university'].tolist()\n",
    "num_of_uni_names_2021 = len(list_of_uni_names_2021)\n",
    "print('There are', num_of_uni_names_2021, 'universities in 2021')\n",
    "\n",
    "dfs_unified_list_uni = list(dfs_unified['university'].unique())\n",
    "num_of_uni_names_dataset = len(dfs_unified_list_uni)\n",
    "print('There are a total of', num_of_uni_names_dataset, 'universities in our dataset')\n",
    "\n",
    "diff_uni_names = num_of_uni_names_dataset - num_of_uni_names_2021\n",
    "print('This means there are a total of', diff_uni_names, 'universities that have a different name than the ones in our 2021 data, and need to be mapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a list with the universities that have different name\n",
    "\n",
    "list_not_matched = []\n",
    "\n",
    "for i in dfs_unified_list_uni:\n",
    "    if i not in list_of_uni_names_2021:\n",
    "        list_not_matched.append(i)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "if len(list_not_matched) != diff_uni_names:\n",
    "    sys.exit()\n",
    "else:\n",
    "    print('list of not matched created successfully')\n",
    "\n",
    "list_not_matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    \"not_matched_uni\": list_not_matched\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    \"list_of_uni_names_2021\": list_of_uni_names_2021\n",
    "})\n",
    "\n",
    "df3 = pd.MultiIndex.from_product(\n",
    "    [df1[\"not_matched_uni\"], df2[\"list_of_uni_names_2021\"]], names=[\"not_matched_uni\", \"list_of_uni_names_2021\"]\n",
    ").to_frame(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['ratio'] = ''\n",
    "\n",
    "for i in range(len(df3['not_matched_uni'])):\n",
    "    df3['ratio'][i] = similar(df3['not_matched_uni'][i], df3['list_of_uni_names_2021'][i])\n",
    "\n",
    "df3['not_matched_uni'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.groupby('not_matched_uni')['ratio'].max().reset_index()\n",
    "\n",
    "df5 = pd.merge(df4,df3,on='not_matched_uni',how='left')\n",
    "df5 = df5[df5['ratio_x'] == df5['ratio_y']]\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacerlo con str.contains, crear funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified['university'] = np.where((dfs_unified['university'] == 'universidad de cantabria (santander)'), 'u. de cantabria (santander)', dfs_unified['university'])\n",
    "dfs_unified['university'] = np.where((dfs_unified['university'] == 'universidad de extremadura (badajoz)'), 'u. de extremadura (badajoz)', dfs_unified['university'])\n",
    "dfs_unified['university'] = np.where((dfs_unified['university'] == 'universidad de jaume i'), 'universidad jaume i', dfs_unified['university'])\n",
    "dfs_unified['university'] = np.where((dfs_unified['university'] == 'universidad de zaragoza - campus de huesca'), 'u. de zaragoza (campus huesca)', dfs_unified['university'])\n",
    "dfs_unified['university'] = np.where((dfs_unified['university'] == 'universidad de santiago de compostela'), 'u. de santiago de compostela', dfs_unified['university'])\n",
    "dfs_unified['university'] = np.where((dfs_unified['university'] == 'universidad de zaragoza - campus de zaragoza'), 'u. de zaragoza (campus zaragoza)', dfs_unified['university'])\n",
    "dfs_unified['university'] = np.where((dfs_unified['university'] == 'universidad miguel hernández (san juan de alicante)'), 'u. miguel hernández (s. juan de alicante)', dfs_unified['university'])\n",
    "dfs_unified['university'] = np.where((dfs_unified['university'] == 'universidad pompeu fabra (barcelona)'), 'u. pompeu fabra (barcelona)', dfs_unified['university'])\n",
    "dfs_unified['university'] = np.where((dfs_unified['university'] == 'universidad de santiago de compostela'), 'u. de santiago de compostela', dfs_unified['university'])\n",
    "dfs_unified['university'] = np.where((dfs_unified['university'] == 'universidad rey juan carlos - campus de alcorcón'), 'urjc - campus alcorcón', dfs_unified['university'])\n",
    "dfs_unified['university'] = np.where((dfs_unified['university'] == 'universidad autónoma de madrid'), 'u. autónoma de madrid', dfs_unified['university'])\n",
    "dfs_unified['university'] = np.where((dfs_unified['university'] == 'universidad de barcelona'), 'universidad de barcelona-clínico', dfs_unified['university'])\n",
    "dfs_unified['university'] = np.where((dfs_unified['university'] == 'universidad de clm- campus de albacete'), 'u. de c-la mancha (campus albacete)', dfs_unified['university'])\n",
    "dfs_unified['university'] = np.where((dfs_unified['university'] == 'universidad de clm- campus de ciudad real'), 'u. de c-la mancha (campus c.real)', dfs_unified['university'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quality check: make sure all university names are mapped with 2021 names\n",
    "\n",
    "dfs_unified_list_uni = list(dfs_unified['university'].unique())\n",
    "\n",
    "list_not_matched = []\n",
    "\n",
    "for i in dfs_unified_list_uni:\n",
    "    if i not in list_of_uni_names_2021:\n",
    "        list_not_matched.append(i)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# checking length of not matched\n",
    "if len(list_not_matched) != 0:\n",
    "    sys.exit()\n",
    "else:\n",
    "    print('all university names are consistent with 2021')\n",
    "\n",
    "# another way of checking this could be by analyzing the overall length and unique names\n",
    "if dfs_unified['university'].nunique() != len(list_of_uni_names_2021):\n",
    "    sys.exit()\n",
    "else:\n",
    "    print('all university names are consistent with 2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if all of the universities have been delivering Medicine career since 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many universities there are per year\n",
    "uni_year_grouped = dfs_unified.groupby(['year'])['university'].count().reset_index()\n",
    "\n",
    "# style\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(12,8))\n",
    "bars = ax.bar(uni_year_grouped['year'], uni_year_grouped['university'])\n",
    "# show number on top of bars\n",
    "ax.bar_label(bars)\n",
    "\n",
    "# title and axis\n",
    "plt.xticks(range(min(uni_year_grouped['year']), max(uni_year_grouped['year']) + 1))\n",
    "plt.yticks(range(min(uni_year_grouped['university']), max(uni_year_grouped['university']) + 1))\n",
    "plt.axis([2009, 2022, 30, 36])\n",
    "plt.title('Number of universities per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of universities')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems like there are 4 universities that haven't been delivering the Medicine career since 2010, let's check which ones they are\n",
    "bool_2010 = {'since_2010': dfs_unified.groupby('university')['university'].count() == 12}\n",
    "bool_2010_df = pd.DataFrame(bool_2010, columns=['since_2010'])\n",
    "bool_2010_df[bool_2010_df['since_2010'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_uni_bb = dfs_unified[dfs_unified['university'] == 'universidad de barcelona-bellvitge']['year'].min()\n",
    "year_uni_ib = dfs_unified[dfs_unified['university'] == 'universidad de las islas baleares']['year'].min()\n",
    "year_uni_ji = dfs_unified[dfs_unified['university'] == 'universidad jaume i']['year'].min()\n",
    "year_uni_pn = dfs_unified[dfs_unified['university'] == 'universidad pública de navarra']['year'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a function tso that we can apply it later to the predicted 2022 data\n",
    "def since_2010():\n",
    "    dfs_unified['since_2010'] = ''\n",
    "    dfs_unified['since_2010'] = np.where(dfs_unified['university'] == 'universidad de barcelona-bellvitge', year_uni_bb, dfs_unified['since_2010'])\n",
    "    dfs_unified['since_2010'] = np.where(dfs_unified['university'] == 'universidad de las islas baleares', year_uni_ib, dfs_unified['since_2010'])\n",
    "    dfs_unified['since_2010'] = np.where(dfs_unified['university'] == 'universidad jaume i', year_uni_ji, dfs_unified['since_2010'])\n",
    "    dfs_unified['since_2010'] = np.where(dfs_unified['university'] == 'universidad pública de navarra', year_uni_pn, dfs_unified['since_2010'])\n",
    "    dfs_unified['since_2010'] = np.where(dfs_unified['since_2010'] == '', True, dfs_unified['since_2010'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since_2010()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified['since_2010'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified[dfs_unified['since_2010'] != True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert columns with numbers to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert to float, we can't have commas or spaces, as this function '.astype(float)' will give back an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float to 2 decimals?? some have 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs_unified['1_list'] = dfs_unified['1_list'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create City and CCAA columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first: bigger cities in case two names appear\n",
    "list_of_cities = ['madrid', 'zaragoza', 'barcelona', 'sevilla', 'valencia', 'murcia', 'granada','málaga', 'córdoba', 'cádiz', 'alicante', 'albacete', \\\n",
    "    'valladolid', 'badajoz', 'gerona', 'lérida', 'reus', 'navarra', 'santander', 'oviedo', \\\n",
    "    'santiago de compostela', 'salamanca', 'bilbao', 'salamanca', 'navarra', 'las palmas', 'la laguna', 'alcalá', 'ciudad real', 'huesca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cities = len(list_of_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a function so that we can apply it later to the predicted 2022 data\n",
    "\n",
    "def city():\n",
    "    i=0\n",
    "    dfs_unified['city'] = ''\n",
    "    while i < num_cities:\n",
    "        dfs_unified['city'] = np.where(dfs_unified['university'].str.contains(list_of_cities[i], na=False), list_of_cities[i], dfs_unified['city'])\n",
    "        i +=1\n",
    "    \n",
    "    dfs_unified['city'] = np.where(dfs_unified['university'].str.contains('país vasco', na=False), 'bilbao', dfs_unified['city'])\n",
    "    dfs_unified['city'] = np.where(dfs_unified['university'].str.contains('alcorcón', na=False), 'madrid', dfs_unified['city'])\n",
    "    dfs_unified['city'] = np.where(dfs_unified['university'].str.contains('c.real', na=False), 'ciudad real', dfs_unified['city'])\n",
    "    dfs_unified['city'] = np.where(dfs_unified['university'].str.contains('jaume', na=False), 'castellon de la plana', dfs_unified['city'])\n",
    "    dfs_unified['city'] = np.where(dfs_unified['university'].str.contains('islas baleares', na=False), 'palma de mallorca', dfs_unified['city'])\n",
    "\n",
    "    num_columns = len(dfs_unified_columns)\n",
    "\n",
    "    while i < num_columns:\n",
    "        dfs_unified[dfs_unified_columns[i]].replace({'': np.nan}, inplace=True)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified[dfs_unified['city'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCAA - Communities of Spain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCAA - communities\n",
    "def CCAA():\n",
    "    dfs_unified['CCAA'] = ''\n",
    "    dfs_unified['CCAA'] = np.where(dfs_unified['city'].isin(['huesca', 'zaragoza']), 'Aragón', dfs_unified['CCAA'])\n",
    "    dfs_unified['CCAA'] = np.where(dfs_unified['city'].isin(['lérida', 'gerona', 'reus', 'barcelona']), 'Cataluña', dfs_unified['CCAA'])\n",
    "    dfs_unified['CCAA'] = np.where(dfs_unified['city'].isin(['madrid', 'alcalá']), 'C. Madrid', dfs_unified['CCAA'])\n",
    "    dfs_unified['CCAA'] = np.where(dfs_unified['city'].isin(['valladolid', 'salamanca']), 'Castilla y León', dfs_unified['CCAA'])\n",
    "    dfs_unified['CCAA'] = np.where(dfs_unified['city'].isin(['santander']), 'Cantabria', dfs_unified['CCAA'])\n",
    "    dfs_unified['CCAA'] = np.where(dfs_unified['city'].isin(['santiago de compostela']), 'Galicia', dfs_unified['CCAA'])\n",
    "    dfs_unified['CCAA'] = np.where(dfs_unified['city'].isin(['badajoz']), 'Extremadura', dfs_unified['CCAA'])\n",
    "    dfs_unified['CCAA'] = np.where(dfs_unified['city'].isin(['cádiz', 'córdoba', 'sevilla', 'málaga', 'granada']), 'Andalucía', dfs_unified['CCAA'])\n",
    "    dfs_unified['CCAA'] = np.where(dfs_unified['city'].isin(['murcia']), 'Murcia', dfs_unified['CCAA'])\n",
    "    dfs_unified['CCAA'] = np.where(dfs_unified['city'].isin(['ciudad real', 'albacete']), 'Castilla-La Mancha', dfs_unified['CCAA'])\n",
    "    dfs_unified['CCAA'] = np.where(dfs_unified['city'].isin(['bilbao']), 'País Vasco', dfs_unified['CCAA'])\n",
    "    dfs_unified['CCAA'] = np.where(dfs_unified['city'].isin(['la laguna', 'las palmas']), 'Canarias', dfs_unified['CCAA'])\n",
    "    dfs_unified['CCAA'] = np.where(dfs_unified['city'].isin(['valencia', 'castellon de la plana', 'alicante']), 'C. Valenciana', dfs_unified['CCAA'])\n",
    "    dfs_unified['CCAA'] = np.where(dfs_unified['city'].isin(['oviedo']), 'Asturias', dfs_unified['CCAA'])\n",
    "    dfs_unified['CCAA'] = np.where(dfs_unified['city'].isin(['palma de mallorca']), 'Islas Baleares', dfs_unified['CCAA'])\n",
    "    dfs_unified['CCAA'] = np.where(dfs_unified['city'].isin(['navarra']), 'Navarra', dfs_unified['CCAA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCAA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified[dfs_unified['CCAA'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified['CCAA'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCAA table for streamlit visualization\n",
    "# df_CCAA = dfs_unified.groupby('CCAA')['final_grade'].mean().reset_index()\n",
    "# df_CCAA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference of 1_list and final_grade scores between years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_between_years(field_name, score):\n",
    "    dfs_unified[field_name] = ''\n",
    "\n",
    "    # year 2010 (initial year)\n",
    "    for uni in list_of_uni_names_2021:\n",
    "        dfs_unified[field_name] = np.where((dfs_unified['university'] == uni) & (dfs_unified['year'] == 2010), np.nan, dfs_unified[field_name])\n",
    "    # rest of years\n",
    "    for uni in list_of_uni_names_2021:\n",
    "        for year in range(2011, 2023):\n",
    "            try:\n",
    "                dfs_unified[field_name] = np.where((dfs_unified['university'] == uni) & (dfs_unified['year'] == year), float((dfs_unified[(dfs_unified['university'] == uni) & (dfs_unified['year'] == year)][score]).values[0] - (dfs_unified[(dfs_unified['university'] == uni) & (dfs_unified['year'] == year - 1)][score]).values[0]), dfs_unified[field_name])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # for the 4 universities that don't have data since 2010\n",
    "    dfs_unified[field_name].replace({'': np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_between_years('diff_1_list', '1_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_between_years('diff_final_grade', 'final_grade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decreased value between 1_list and final_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decresead value from 1_list to final grade\n",
    "def diff_1_list_final_grade():\n",
    "    dfs_unified['diff_1_list_final_grade'] = dfs_unified['1_list'] - dfs_unified['final_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_1_list_final_grade()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covid format change: change in test format due to covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare 1_list growth of years before 2020, and in 2020\n",
    "grouped_year_1_list = dfs_unified.groupby('year')['diff_1_list'].mean().reset_index()\n",
    "\n",
    "# round to 3 decimals\n",
    "grouped_year_1_list['diff_1_list'] = grouped_year_1_list['diff_1_list'].apply(lambda x: round(x, 3))\n",
    "\n",
    "# since we don't have data from 2009, we are excluding 2010\n",
    "# we are also excluding 2021 since it's not relevant to show the growth before and after covid\n",
    "grouped_year_1_list = grouped_year_1_list[(grouped_year_1_list['year'] != 2010) & (grouped_year_1_list['year'] != 2021)]\n",
    "\n",
    "grouped_year_1_list_before_2020 = grouped_year_1_list[grouped_year_1_list['year'] < 2020]\n",
    "grouped_year_1_list_in_2020 = grouped_year_1_list[grouped_year_1_list['year'] == 2020]\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(12,8))\n",
    "bars = ax.bar(grouped_year_1_list['year'], grouped_year_1_list['diff_1_list'])\n",
    "# show number on top of bars\n",
    "ax.bar_label(bars)\n",
    "# style\n",
    "plt.style.use('ggplot')\n",
    "# title and axis\n",
    "plt.xticks(range(min(grouped_year_1_list['year']), max(grouped_year_1_list['year']) + 1))\n",
    "plt.title('Average difference of 1_list scores across years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Avg diff of 1_list scores between curr and prev year')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('average 1_list difference before 2020 is: ', grouped_year_1_list_before_2020['diff_1_list'].mean())\n",
    "print('average 1_list difference in 2020 is: ',grouped_year_1_list_in_2020['diff_1_list'].mean())\n",
    "print('The difference between average before 2020 and average in 2020 is x',grouped_year_1_list_in_2020['diff_1_list'].mean() / grouped_year_1_list_before_2020['diff_1_list'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change in test format due to covid\n",
    "\n",
    "def covid_format_change():\n",
    "    dfs_unified['covid_format_change'] = ''\n",
    "    dfs_unified['covid_format_change'] = np.where((dfs_unified['year'] >= 2020), float(1), dfs_unified['covid_format_change'])\n",
    "    dfs_unified['covid_format_change'] = np.where((dfs_unified['year'] < 2020), float(0), dfs_unified['covid_format_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_format_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round columns above to 3 decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round numbers to 3 decimals\n",
    "def round_to_3():\n",
    "    dfs_unified['1_list'] = dfs_unified['1_list'].apply(lambda x: round(x, 3))\n",
    "    dfs_unified['final_grade'] = dfs_unified['final_grade'].apply(lambda x: round(x, 3))\n",
    "    dfs_unified['diff_final_grade'] = dfs_unified['diff_final_grade'].apply(lambda x: round(x, 3))\n",
    "    dfs_unified['diff_1_list'] = dfs_unified['diff_1_list'].apply(lambda x: round(x, 3))\n",
    "    dfs_unified['diff_1_list_final_grade'] = dfs_unified['diff_1_list_final_grade'].apply(lambda x: round(x, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_to_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shorter name of universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified['university'] = dfs_unified['university'].replace('universidad', 'u.', regex=True)\n",
    "list_of_uni_names_2021  = dfs_unified[dfs_unified['year'] == last_year]['university'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude and Longitude of Universities for map on Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.mapcoordinates.net/es\n",
    "\n",
    "def latitude():\n",
    "    dfs_unified['latitude'] = ''\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. autónoma de barcelona', 41.5025932, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de lérida', 41.81636125, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de gerona', 41.9743792, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. rovira i virgili (reus)', 41.155309, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de zaragoza (campus huesca)', 42.1414059, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de valladolid', 41.6105937, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de cantabria (santander)', 43.4736983, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de santiago de compostela', 42.88050025, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de extremadura (badajoz)', 38.8824069, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de cádiz', 36.5340199, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. pompeu fabra (barcelona)', 41.37921475, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de barcelona-clínico', 41.39017434, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de salamanca', 40.9666432, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de zaragoza (campus zaragoza)', 41.6421312, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de c-la mancha (campus c.real)', 38.9918372, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de córdoba', 37.8560421, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. del país vasco (lejona)', 43.3359821, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de c-la mancha (campus albacete)', 38.4527362, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de sevilla', 37.4128557, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. miguel hernández (s. juan de alicante)', 38.39896277, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de alcalá', 40.4818396, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de málaga', 36.7200431, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de murcia', 37.99109245, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de la laguna', 28.4852475, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'urjc - campus alcorcón', 40.3506324, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de valencia', 39.4786642, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. autónoma de madrid', 40.4832261, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de las palmas', 28.09055808, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de granada', 37.1474408, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. complutense de madrid', 40.4437398, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de oviedo', 43.3533657, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. jaume i', 39.9899483, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de las islas baleares', 39.60701435, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. pública de navarra', 42.8154264, dfs_unified['latitude'])\n",
    "    dfs_unified['latitude'] = np.where(dfs_unified['university'] == 'u. de barcelona-bellvitge', 41.3507816, dfs_unified['latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longitude():\n",
    "    dfs_unified['longitude'] = ''\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. autónoma de barcelona', 2.080056, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de lérida', 1.59713745, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de gerona', 2.8235429, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. rovira i virgili (reus)', 1.1053273, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de zaragoza (campus huesca)', -0.4060896, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de valladolid', -4.6916619, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de cantabria (santander)', -3.7859174, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de santiago de compostela', -8.5457602, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de extremadura (badajoz)', -7.0194457, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de cádiz', -6.3018987, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. pompeu fabra (barcelona)', 2.17941527, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de barcelona-clínico', 2.15212588, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de salamanca', -5.6772757, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de zaragoza (campus zaragoza)', -0.90302271, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de c-la mancha (campus c.real)', -3.9268263, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de córdoba', -4.8134452, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. del país vasco (lejona)', -2.9768285, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de c-la mancha (campus albacete)', -2.05363374, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de sevilla', -5.9845606, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. miguel hernández (s. juan de alicante)', -0.43477806, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de alcalá', -3.3644973, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de málaga', -4.41617939, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de murcia', -1.13010405, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de la laguna', -16.3126059, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'urjc - campus alcorcón', -3.8437926, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de valencia', -0.3627246, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. autónoma de madrid', -3.6972262, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de las palmas', -15.41890014, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de granada', -3.6042349, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. complutense de madrid', -3.72614639, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de oviedo', -5.8687712, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. jaume i', -0.0664218, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de las islas baleares', 2.64475448, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. pública de navarra', -1.65263107, dfs_unified['longitude'])\n",
    "    dfs_unified['longitude'] = np.where(dfs_unified['university'] == 'u. de barcelona-bellvitge', 2.1045067, dfs_unified['longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude()\n",
    "longitude()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified[dfs_unified['latitude'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified[dfs_unified['longitude'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified[dfs_unified['latitude'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified[dfs_unified['longitude'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified_columns = dfs_unified.columns.tolist()[1:]\n",
    "\n",
    "num_columns = len(dfs_unified_columns)\n",
    "\n",
    "for i in range(num_columns):\n",
    "    dfs_unified[dfs_unified_columns[i]].replace({np.nan: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ojo que paso los nan a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,8))         # Sample figsize in inches\n",
    "sns.heatmap(dfs_unified.corr(), annot=True, fmt=\".2f\", linewidths=.5, ax=ax, cmap='RdBu')\n",
    "plt.title('Correlation between variables');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the output variable (1_list) is a number we need to solve a regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actual_vs_predicted(title_string, subtitle_string, y_test, y_predict, year):\n",
    "    # visualize the predicted score as a line on the test set\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.scatter(dfs_unified[dfs_unified['year'] == year]['university'], y_test, color = 'red', label = 'actual')\n",
    "    plt.plot(dfs_unified[dfs_unified['year'] == year]['university'], y_predict, color='g', label = 'predicted')\n",
    "    plt.xlabel('University', fontsize = 14)\n",
    "    plt.ylabel('1_list', fontsize = 14)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.suptitle(title_string, y=1.05, fontsize=18)\n",
    "    plt.title(subtitle_string, fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.style.use('ggplot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_models = pd.DataFrame(columns=['model_name_variables', 'MSE', 'RMSE', 'MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics():\n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "    df_MSE = results_models[['MSE']]\n",
    "    df_RMSE = results_models[['RMSE']]\n",
    "    df_MAE = results_models[['MAE']]\n",
    "\n",
    "    # sort values so the best model appears in first position\n",
    "    df_MSE = df_MSE.sort_values('MSE', ascending=False)\n",
    "    df_RMSE = df_RMSE.sort_values('RMSE', ascending=False)\n",
    "    df_MAE = df_MAE.sort_values('MAE', ascending=False)\n",
    "\n",
    "    # create figure and one axis per metric\n",
    "    f = plt.figure(figsize=(10,20))\n",
    "    axes1 = f.add_subplot(4,1,1)\n",
    "    axes2 = f.add_subplot(4,1,2)\n",
    "    axes3 = f.add_subplot(4,1,3)\n",
    "        \n",
    "    # plot dataframes with DataFrame.plot()\n",
    "    df_MSE.plot(kind='barh', ax=axes1, color='lightgreen', title = 'Compare Model Metrics')\\\n",
    "            .legend(loc='lower left',bbox_to_anchor=(1.0, 0.5))\n",
    "    df_RMSE.plot(kind='barh', ax=axes2, color='lightskyblue')\\\n",
    "            .legend(loc='lower left',bbox_to_anchor=(1.0, 0.5))\n",
    "    df_MAE.plot(kind='barh',ax=axes3, color='salmon')\\\n",
    "            .legend(loc='lower left',bbox_to_anchor=(1.0, 0.5))  \n",
    "        \n",
    "    # annotate bars with result values \n",
    "    for p in axes1.patches:\n",
    "            axes1.annotate(np.round(a=p.get_width(), decimals=3), \\\n",
    "                    (p.get_x() + p.get_width(), p.get_y()), \\\n",
    "                    xytext=(-30, 5), textcoords='offset points')\n",
    "\n",
    "    for p in axes2.patches:\n",
    "            axes2.annotate(np.round(a=p.get_width(), decimals=3), \\\n",
    "                    (p.get_x() + p.get_width(), p.get_y()), \\\n",
    "                    xytext=(-30, 5), textcoords='offset points')\n",
    "\n",
    "    for p in axes3.patches:\n",
    "            axes3.annotate(np.round(a=p.get_width(), decimals=3), \\\n",
    "                    (p.get_x() + p.get_width(), p.get_y()), \\\n",
    "                    xytext=(-30, 5), textcoords='offset points')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data will be years 2011-2020, Test data will be year 2021, and Validation data year 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X_var, model_name_variables):\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    X_train = dfs_unified[(dfs_unified['year'] != 2021) & (dfs_unified['year'] != 2011)][X_var]\n",
    "    y_train = dfs_unified[(dfs_unified['year'] != 2021) & (dfs_unified['year'] != 2011)][['1_list']]\n",
    "\n",
    "    X_test = dfs_unified[(dfs_unified['year'] == 2021)][X_var]\n",
    "    y_test = dfs_unified[(dfs_unified['year'] == 2021)][['1_list']]\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_predict = lr.predict(X_test) # we are predicting the 1_list scores for 2021, for all of the universities (various scores)\n",
    "    \n",
    "    \n",
    "    # evaluation\n",
    "    errors = y_test - y_predict\n",
    "\n",
    "    # MSE (min squared error)\n",
    "    mse = float(np.mean(errors ** 2))\n",
    "\n",
    "    # RMSE (root min squared error)\n",
    "    rmse = float(np.sqrt(mse))\n",
    "\n",
    "    # MAE (mean absolute error)\n",
    "    mae = float(np.mean(np.abs(errors)))\n",
    "    \n",
    "    results_models.loc[model_name_variables] = [model_name_variables, mse, rmse, mae]\n",
    "\n",
    "    plot_actual_vs_predicted('Linear Regression: For 2021, actual 1_list scores vs predicted', f'Variables: {X_var}', y_test, y_predict, 2021)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using only \"final_grade\" variable\n",
    "\n",
    "linear_regression(['final_grade'], 'linear_regression_final_grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using \"final_grade\" and \"year\" variables\n",
    "linear_regression(['final_grade', 'year'], 'linear_regression_final_grade_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using \"final_grade\", \"year\" and \"covid_format_change\" variables\n",
    "linear_regression(['final_grade', 'year', 'covid_format_change'], 'linear_regression_final_grade_year_covid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using \"final_grade\", \"year\", \"covid_format_change\" and \"diff_1_list\"  variables\n",
    "linear_regression(['final_grade', 'year', 'covid_format_change', 'diff_1_list'], 'linear_regression_final_grade_year_covid_diff_1_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression per University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate models per university\n",
    "results_models_per_uni = pd.DataFrame(columns=['university','MSE', 'RMSE', 'MAE', 'y_predict', 'y_test'])\n",
    "results_models_per_uni['university'] = list_of_uni_names_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_per_uni(X_var, model_name_variables):\n",
    "    lr = LinearRegression()\n",
    "    X_train = dfs_unified[(dfs_unified['university'] == uni) & (dfs_unified['year'] != 2021) & (dfs_unified['year'] != 2011)][X_var]\n",
    "    y_train = dfs_unified[(dfs_unified['university'] == uni) & (dfs_unified['year'] != 2021) & (dfs_unified['year'] != 2011)][['1_list']]\n",
    "\n",
    "    X_test = dfs_unified[(dfs_unified['university'] == uni) & (dfs_unified['year'] == 2021)][X_var]\n",
    "    y_test = dfs_unified[(dfs_unified['university'] == uni) & (dfs_unified['year'] == 2021)][['1_list']]\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_predict = lr.predict(X_test) # we are predicting the 1_list score from 2021 for a specific university (only 1 score)\n",
    "    y_predict = float(y_predict)\n",
    "    y_test = y_test['1_list'].values[0]\n",
    "\n",
    "    # evaluation\n",
    "    errors = y_test - y_predict\n",
    "\n",
    "    # MSE (min squared error)\n",
    "    mse = np.mean(errors ** 2)\n",
    "\n",
    "    # RMSE (root min squared error)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # MAE (mean absolute error)\n",
    "    mae = np.mean(np.abs(errors))\n",
    "    \n",
    "    results_models_per_uni['MSE'] = np.where(results_models_per_uni['university'] == uni, mse, results_models_per_uni['MSE'])\n",
    "    results_models_per_uni['RMSE'] = np.where(results_models_per_uni['university'] == uni, rmse, results_models_per_uni['RMSE'])\n",
    "    results_models_per_uni['MAE'] = np.where(results_models_per_uni['university'] == uni, mae, results_models_per_uni['MAE'])\n",
    "    results_models_per_uni['y_predict'] = np.where(results_models_per_uni['university'] == uni, y_predict, results_models_per_uni['y_predict'])\n",
    "    results_models_per_uni['y_test'] = np.where(results_models_per_uni['university'] == uni, y_test, results_models_per_uni['y_test'])\n",
    "\n",
    "    # we do the average out of all of the universities, to compare against the other models\n",
    "    results_models.loc[model_name_variables] = [model_name_variables, results_models_per_uni['MSE'].mean(), results_models_per_uni['RMSE'].mean(), results_models_per_uni['MAE'].mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using only \"final_grade\" variable\n",
    "\n",
    "X_var = ['final_grade']\n",
    "\n",
    "for uni in list_of_uni_names_2021:\n",
    "    linear_regression_per_uni(X_var, 'linear_regression_per_uni_final_grade')\n",
    "\n",
    "y_test = results_models_per_uni['y_test']\n",
    "y_predict = results_models_per_uni['y_predict']\n",
    "\n",
    "plot_actual_vs_predicted('Linear Regression Per University: For 2021, actual 1_list scores vs predicted', f'Variables: {X_var}', y_test, y_predict, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using \"final_grade\" and \"year\" variables\n",
    "\n",
    "X_var = ['final_grade', 'year']\n",
    "\n",
    "for uni in list_of_uni_names_2021:\n",
    "    linear_regression_per_uni(X_var, 'linear_regression_per_uni_final_grade_year')\n",
    "\n",
    "y_test = results_models_per_uni['y_test']\n",
    "y_predict = results_models_per_uni['y_predict']\n",
    "\n",
    "plot_actual_vs_predicted('Linear Regression Per University: For 2021, actual 1_list scores vs predicted', f'Variables: {X_var}', y_test, y_predict, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using \"final_grade\", \"year\" and \"covid_format_change\" variables\n",
    "\n",
    "X_var = ['final_grade', 'year', 'covid_format_change']\n",
    "\n",
    "for uni in list_of_uni_names_2021:\n",
    "    linear_regression_per_uni(X_var, 'linear_regression_per_uni_final_grade_year_covid')\n",
    "\n",
    "y_test = results_models_per_uni['y_test']\n",
    "y_predict = results_models_per_uni['y_predict']\n",
    "\n",
    "plot_actual_vs_predicted('Linear Regression Per University: For 2021, actual 1_list scores vs predicted', f'Variables: {X_var}', y_test, y_predict, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using \"final_grade\", \"year\", \"covid_format_change\" and \"diff_1_list\"  variables\n",
    "\n",
    "X_var = ['final_grade', 'year', 'covid_format_change', 'diff_1_list']\n",
    "\n",
    "for uni in list_of_uni_names_2021:\n",
    "    linear_regression_per_uni(X_var, 'linear_regression_per_uni_final_grade_year_covid_diff_1_list')\n",
    "\n",
    "y_test = results_models_per_uni['y_test']\n",
    "y_predict = results_models_per_uni['y_predict']\n",
    "\n",
    "plot_actual_vs_predicted('Linear Regression Per University: For 2021, actual 1_list scores vs predicted', f'Variables: {X_var}', y_test, y_predict, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given that the metrics are quite below the mean score of the variable we are predicting, we can consider the models are efficient\n",
    "\n",
    "dfs_unified['1_list'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA per University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pmdarima --upgrade\n",
    "#!pip install statsmodels==0.11.0rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "#import pandas.util.testing as tm\n",
    "\n",
    "def ad_test(dataset):\n",
    "    dftest = adfuller(dataset, autolag = 'AIC')\n",
    "    print('1. ADF: ', dftest[0])\n",
    "    print('2. P-Value: ', dftest[1])\n",
    "    print('3. Num Of Lags: ', dftest[2])\n",
    "    print('4. Num Of Observations Used For ADF Regression and Critical Values Calculation: ', dftest[3])\n",
    "    print('5. Critical Values: ')\n",
    "    for key, val in dftest[4].items():\n",
    "        print('\\t', key, ': ', val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_test(dfs_unified['1_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "#from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in train and test\n",
    "university = 'u. complutense de madrid'\n",
    "train = dfs_unified[(dfs_unified['university'] == university) & (dfs_unified['year'] != 2021) & (dfs_unified['year'] != 2011)][['1_list']]\n",
    "test = dfs_unified[(dfs_unified['university'] == university) & (dfs_unified['year'] == 2021)][['1_list']]\n",
    "\n",
    "#print(dfs_unified.shape)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified[(dfs_unified['university'] == university)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARIMACheck(university):\n",
    "    from pmdarima import auto_arima  \n",
    "\n",
    "    stepwise_fit = auto_arima(dfs_unified[dfs_unified['university'] == university]['1_list'], trace=True, suppress_warnings=True)\n",
    "    #print(stepwise_fit.summary())\n",
    "    return stepwise_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_fit = ARIMACheck(university)\n",
    "stepwise_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_fit.get_params().get('order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(train, order=stepwise_fit.get_params().get('order'))\n",
    "model = model.fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for test set (2021 scores)\n",
    "start = len(train)\n",
    "end = len(train) + len(test)-1\n",
    "y_predict = model.predict(start=start, end=end, typ='levels')\n",
    "y_predict.index = dfs_unified[(dfs_unified['university'] == university) & (dfs_unified['year'] == 2021)]['university']\n",
    "y_predict_df = y_predict.reset_index()\n",
    "y_predict_df['1_list'] = ''\n",
    "y_predict_df['1_list'] = y_predict_df[0]\n",
    "y_predict_df = y_predict_df.drop(0, 1)\n",
    "y_predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['1_list'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['1_list'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate models per university\n",
    "arima_results_models_per_uni = pd.DataFrame(columns=['university','MSE', 'RMSE', 'MAE', 'y_predict', 'y_test'])\n",
    "arima_results_models_per_uni['university'] = list_of_uni_names_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARIMA_per_uni(model_name_variables):\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    \n",
    "    # split data in train and test\n",
    "    train = dfs_unified[(dfs_unified['university'] == uni) & (dfs_unified['year'] != 2021) & (dfs_unified['year'] != 2011)][['1_list']]\n",
    "    test = dfs_unified[(dfs_unified['university'] == uni) & (dfs_unified['year'] == 2021)][['1_list']]\n",
    "\n",
    "    stepwise_fit = ARIMACheck(uni)\n",
    "\n",
    "    model = ARIMA(train, order=stepwise_fit.get_params().get('order'))\n",
    "    model = model.fit()\n",
    "    \n",
    "    # prediction for test set (2021 scores)\n",
    "    start = len(train)\n",
    "    end = len(train) + len(test)-1\n",
    "    y_predict = model.predict(start=start, end=end, typ='levels')\n",
    "    # y_predict.index = dfs_unified[(dfs_unified['university'] == university) & (dfs_unified['year'] == 2021)]['university']\n",
    "    # y_predict_df['university'] = np.where(y_predict_df['university'] == university, university, y_predict_df['university'])\n",
    "    # y_predict_df['1_list'] = np.where(y_predict_df['university'] == university, pred.mean(), y_predict_df['1_list'])\n",
    "    \n",
    "    y_predict = y_predict.values[0]\n",
    "    y_test = test['1_list'].values[0]\n",
    "\n",
    "    # evaluation\n",
    "    errors = y_test - y_predict\n",
    "\n",
    "    # MSE (min squared error)\n",
    "    mse = np.mean(errors ** 2)\n",
    "\n",
    "    # RMSE (root min squared error)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # MAE (mean absolute error)\n",
    "    mae = np.mean(np.abs(errors))\n",
    "    \n",
    "    arima_results_models_per_uni['MSE'] = np.where(arima_results_models_per_uni['university'] == uni, mse, arima_results_models_per_uni['MSE'])\n",
    "    arima_results_models_per_uni['RMSE'] = np.where(arima_results_models_per_uni['university'] == uni, rmse, arima_results_models_per_uni['RMSE'])\n",
    "    arima_results_models_per_uni['MAE'] = np.where(arima_results_models_per_uni['university'] == uni, mae, arima_results_models_per_uni['MAE'])\n",
    "    arima_results_models_per_uni['y_predict'] = np.where(arima_results_models_per_uni['university'] == uni, y_predict, arima_results_models_per_uni['y_predict'])\n",
    "    arima_results_models_per_uni['y_test'] = np.where(arima_results_models_per_uni['university'] == uni, y_test, arima_results_models_per_uni['y_test'])\n",
    "\n",
    "    # we do the average out of all of the universities, to compare against the other models\n",
    "    results_models.loc[model_name_variables] = [model_name_variables, arima_results_models_per_uni['MSE'].mean(), arima_results_models_per_uni['RMSE'].mean(), arima_results_models_per_uni['MAE'].mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_of_uni_names_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install statsmodels --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uni in list_of_uni_names_2021:\n",
    "    print(uni)\n",
    "    try:\n",
    "        ARIMA_per_uni('ARIMA_per_uni')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_results_models_per_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified[(dfs_unified['university'] == 'u. de barcelona-bellvitge') & (dfs_unified['year'] != 2021)][['1_list']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for u. de barcelona-bellvitge we only have data since 2020, therefore we get an error when trying to calculate the scores\n",
    "# for this case, let's suppose there is no growth (same score for 2021 as 2020)\n",
    "\n",
    "uni = 'u. de barcelona-bellvitge'\n",
    "y_predict = dfs_unified[(dfs_unified['university'] == uni) & (dfs_unified['year'] != 2021)][['1_list']].mean()\n",
    "y_test = dfs_unified[(dfs_unified['university'] == uni) & (dfs_unified['year'] == 2021)][['1_list']].mean()\n",
    "\n",
    "# evaluation\n",
    "errors = y_test - y_predict\n",
    "\n",
    "# MSE (min squared error)\n",
    "mse = np.mean(errors ** 2)\n",
    "\n",
    "# RMSE (root min squared error)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# MAE (mean absolute error)\n",
    "mae = np.mean(np.abs(errors))\n",
    "    \n",
    "arima_results_models_per_uni['MSE'] = np.where(arima_results_models_per_uni['university'] == uni, mse, arima_results_models_per_uni['MSE'])\n",
    "arima_results_models_per_uni['RMSE'] = np.where(arima_results_models_per_uni['university'] == uni, rmse, arima_results_models_per_uni['RMSE'])\n",
    "arima_results_models_per_uni['MAE'] = np.where(arima_results_models_per_uni['university'] == uni, mae, arima_results_models_per_uni['MAE'])\n",
    "arima_results_models_per_uni['y_predict'] = np.where(arima_results_models_per_uni['university'] == uni, y_predict, arima_results_models_per_uni['y_predict'])\n",
    "arima_results_models_per_uni['y_test'] = np.where(arima_results_models_per_uni['university'] == uni, y_test, arima_results_models_per_uni['y_test'])\n",
    "\n",
    "    # we do the average out of all of the universities, to compare against the other models\n",
    "results_models.loc['ARIMA_per_uni'] = ['ARIMA_per_uni', arima_results_models_per_uni['MSE'].mean(), arima_results_models_per_uni['RMSE'].mean(), arima_results_models_per_uni['MAE'].mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_results_models_per_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_var = ['1_list']\n",
    "plot_actual_vs_predicted('ARIMA Per University: For 2021, actual 1_list scores vs predicted', f'Variables: {X_var}', arima_results_models_per_uni['y_test'], arima_results_models_per_uni['y_predict'], 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if there is Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to check two things:\n",
    "- graph of predicted vs actual 1_list values for validation data (year: 2011)\n",
    "- plot and compare metrics of the validation data and the test data, they should be similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_uni_names_2011 = dfs_unified[dfs_unified['year'] == 2011]['university'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate models per university\n",
    "results_models_per_uni = pd.DataFrame(columns=['university','MSE', 'RMSE', 'MAE', 'y_predict', 'y_val'])\n",
    "results_models_per_uni['university'] = list_of_uni_names_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_per_uni(X_var, model_name_variables):\n",
    "    lr = LinearRegression()\n",
    "    X_train = dfs_unified[(dfs_unified['university'] == uni) & (dfs_unified['year'] != 2021) & (dfs_unified['year'] != 2011)][X_var]\n",
    "    y_train = dfs_unified[(dfs_unified['university'] == uni) & (dfs_unified['year'] != 2021) & (dfs_unified['year'] != 2011)][['1_list']]\n",
    "\n",
    "    X_val = dfs_unified[(dfs_unified['university'] == uni) & (dfs_unified['year'] == 2011)][X_var]\n",
    "    y_val = dfs_unified[(dfs_unified['university'] == uni) & (dfs_unified['year'] == 2011)][['1_list']]\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_predict = lr.predict(X_val) # we are predicting the 1_list score from 2021 for a specific university (only 1 score)\n",
    "    y_predict = float(y_predict)\n",
    "    y_val = y_val['1_list'].values[0]\n",
    "\n",
    "    # evaluation\n",
    "    errors = y_val - y_predict\n",
    "\n",
    "    # MSE (min squared error)\n",
    "    mse = np.mean(errors ** 2)\n",
    "\n",
    "    # RMSE (root min squared error)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # MAE (mean absolute error)\n",
    "    mae = np.mean(np.abs(errors))\n",
    "    \n",
    "    results_models_per_uni['MSE'] = np.where(results_models_per_uni['university'] == uni, mse, results_models_per_uni['MSE'])\n",
    "    results_models_per_uni['RMSE'] = np.where(results_models_per_uni['university'] == uni, rmse, results_models_per_uni['RMSE'])\n",
    "    results_models_per_uni['MAE'] = np.where(results_models_per_uni['university'] == uni, mae, results_models_per_uni['MAE'])\n",
    "    results_models_per_uni['y_predict'] = np.where(results_models_per_uni['university'] == uni, y_predict, results_models_per_uni['y_predict'])\n",
    "    results_models_per_uni['y_val'] = np.where(results_models_per_uni['university'] == uni, y_val, results_models_per_uni['y_val'])\n",
    "\n",
    "    # we do the average out of all of the universities, to compare against the other models\n",
    "    results_models.loc[model_name_variables] = [model_name_variables, results_models_per_uni['MSE'].mean(), results_models_per_uni['RMSE'].mean(), results_models_per_uni['MAE'].mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using \"final_grade\", \"year\" and \"covid_format_change\" variables\n",
    "\n",
    "X_var = ['final_grade', 'year', 'covid_format_change']\n",
    "\n",
    "for uni in list_of_uni_names_2011:\n",
    "    linear_regression_per_uni(X_var, 'linear_regression_per_uni_final_grade_year_covid_VALIDATION')\n",
    "\n",
    "y_val = results_models_per_uni['y_val']\n",
    "y_predict = results_models_per_uni['y_predict']\n",
    "\n",
    "plot_actual_vs_predicted('Linear Regression Per University: For 2011, actual 1_list scores vs predicted', f'Variables: {X_var}', y_val, y_predict, 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict 2022 1_list scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the metrics results shown above, we will use the Linear Regression per University models with the variables: \"final_grade\", \"year\" and \"covid_format_change\" to predict the scores for 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we now the model is good, we retrain the model on the entire dataset (not only the train section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_df = pd.DataFrame(columns=['year', 'university', '1_list'])\n",
    "pred_y_df['university'] = list_of_uni_names_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_save_scores(year, covid_format_change, university):\n",
    "    '''\n",
    "    explicar\n",
    "    '''\n",
    "    lr = LinearRegression()\n",
    "    X = dfs_unified[dfs_unified['university'] == university][['final_grade', 'year', 'covid_format_change']]\n",
    "    y = dfs_unified[dfs_unified['university'] == university][['1_list']]\n",
    "\n",
    "    # train\n",
    "    lr.fit(X, y)\n",
    "    \n",
    "    # predict, supposing final_grade as previous year's final_grade\n",
    "    final_grade = dfs_unified[dfs_unified['university'] == university]['final_grade'][-1:].mean()\n",
    "    \n",
    "    pred_y_df['1_list'] = np.where(pred_y_df['university'] == university, float(lr.predict([[final_grade, year, covid_format_change]])), pred_y_df['1_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uni in list_of_uni_names_2021:\n",
    "    predict_and_save_scores(2022, 1.0, uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problema: 1_list no puede ser menor que final_grade | lo calculamos sin utilizar el modelo, cogemos el decrecimiento del último año y se lo restamos a 1_list predicted\n",
    "pred_y_df['final_grade'] = ''\n",
    "\n",
    "for uni in list_of_uni_names_2021:\n",
    "    pred_y_df['final_grade'] = np.where(pred_y_df['university'] == uni, pred_y_df['1_list'] - dfs_unified[dfs_unified['university'] == uni]['diff_1_list_final_grade'][-1:].mean(), pred_y_df['final_grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_df['year'] = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append predicted scores to dfs_unified\n",
    "\n",
    "dfs_unified = dfs_unified.append(pred_y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply created columns to predicted data (2022)\n",
    "since_2010()\n",
    "city()\n",
    "CCAA()\n",
    "covid_format_change()\n",
    "diff_between_years('diff_1_list', '1_list')\n",
    "diff_between_years('diff_final_grade', 'final_grade')\n",
    "diff_1_list_final_grade()\n",
    "round_to_3()\n",
    "latitude()\n",
    "longitude()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified[dfs_unified['year'] == 2022]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_data_directory = your_directory + '/output'\n",
    "exported_data_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data to be used on streamlit\n",
    "file_name = exported_data_directory + '/exported_data_notebook.csv'\n",
    "dfs_unified.to_csv(file_name, index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified[dfs_unified.isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_unified[dfs_unified['university'] == '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Front-end / Streamlit visualization (myapp.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install streamlit\n",
    "#!streamlit run /Users/miguel/repos/Prediction_Medicine_Selectivity_Scores/streamlit/myapp.py"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afc3b4600e7999c1cec994f4f7321fa76de0c7f2f3bd5869f8f64fa643bd8b36"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
